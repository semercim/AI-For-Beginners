{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evrişimli Sinir Ağları\n",
    "\n",
    "Önceki ünitede, sınıf tanımını kullanarak çok katmanlı bir sinir ağının nasıl tanımlanacağını öğrenmiştik, ancak bu ağlar geneldi ve bilgisayarla görme görevleri için özelleşmiş değildi. Bu ünitede özellikle bilgisayarla görme için tasarlanmış **Evrişimli Sinir Ağları (CNN'ler)** hakkında bilgi edineceğiz.\n",
    "\n",
    "Bilgisayarla görme, genel sınıflandırmadan farklıdır çünkü resimde belirli bir nesneyi bulmaya çalışırken, belirli **örüntüleri** ve bunların kombinasyonlarını arayarak imgeyi tarıyoruz. Örneğin, bir kedi ararken, önce bıyık oluşturabilen yatay çizgilere bakabiliriz ve ardından belirli bir bıyık kombinasyonu bize bunun aslında bir kedi resmi olduğunu söyleyebilir. İmge üzerindeki tam konumları değil, belirli modellerin göreli konumu ve varlığı önemlidir.\n",
    "\n",
    "Örüntüleri çıkarmak için **evrişimli filtreler** kavramını kullanacağız. Ama önce önceki ünitelerde tanımladığımız tüm bağımlılıkları ve fonksiyonları yükleyelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary\n",
    "import numpy as np\n",
    "\n",
    "from pytorchcv import load_mnist, train, plot_results, plot_convolution, display_dataset\n",
    "load_mnist(batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evrişimli filtreler\n",
    "\n",
    "Evrişimli filtreler, imgenin her pikseli üzerinde çalışan ve komşu piksellerin ağırlıklı ortalamasını hesaplayan küçük pencerelerdir.\n",
    "\n",
    "\n",
    "\n",
    "Ağırlık katsayı matrisleriyle tanımlanırlar. MNIST el yazısı rakamlarımız üzerinde iki farklı evrişimli filtre uygulama örneği görelim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_convolution(torch.tensor([[-1.,0.,1.],[-1.,0.,1.],[-1.,0.,1.]]),'Dikey kenar filtresi')\n",
    "plot_convolution(torch.tensor([[-1.,-1.,-1.],[0.,0.,0.],[1.,1.,1.]]),'Yatay kenar filtresi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "İlk filtre **dikey kenar filtresi** olarak adlandırılır ve aşağıdaki matris ile tanımlanır:\n",
    "$$\n",
    "\\left(\n",
    "    \\begin{matrix}\n",
    "     -1 & 0 & 1 \\cr\n",
    "     -1 & 0 & 1 \\cr\n",
    "     -1 & 0 & 1 \\cr\n",
    "    \\end{matrix}\n",
    "\\right)\n",
    "$$\n",
    "Bu filtre nispeten tekdüze bir piksel alanı üzerinden geçtiğinde, tüm değerler  0'a toplar. Ancak, imgede dikey bir kenarla karşılaştığında, yüksek uç değer üretilir. Bu nedenle yukarıdaki imgelerde dikey kenarların yüksek ve düşük değerlerle temsil edildiğini, yatay kenarların ise ortalamasının alındığını görebilirsiniz.\n",
    "\n",
    "Yatay kenar filtresi uyguladığımızda tam tersi bir şey olur - yatay çizgiler büyütülür ve dikey çizgiler ortalanır.\n",
    "\n",
    "Klasik bilgisayarla görmede, öznitelikler oluşturmak için imgeye birden çok filtre uygulandı ve bunlar daha sonra bir sınıflandırıcı oluşturmak için makine öğrenmesi algoritması tarafından kullanıldı. Bununla birlikte, derin öğrenmede, sınıflandırma problemini çözmek için en iyi evrişimli filtreleri **öğrenen** ağlar oluştururuz.\n",
    "\n",
    "Bunu yapmak için **evrişimli katmanları** tanıtıyoruz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evrişimli Katmanlar\n",
    "\n",
    "Evrişimli katmanlar, `nn.Conv2d` yapısı kullanılarak tanımlanır. Aşağıdakileri belirtmemiz gerekiyor:\n",
    "* `in_channels` - girdi kanallarının sayısı. Bizim durumumuzda gri tonlamalı bir imgeyle uğraşıyoruz, bu nedenle girdi kanallarının sayısı 1'dir.\n",
    "* `out_channels` - kullanılacak filtre sayısı. 9 farklı filtre kullanacağız, bu da ağa senaryomuz için hangi filtrelerin en iyi şekilde çalıştığını keşfetme fırsatı verecektir.\n",
    "* `kernel_size` kayan pencerenin boyutudur. Genellikle 3x3 veya 5x5 filtreler kullanılır.\n",
    "\n",
    "En basit CNN, bir evrişimli katman içerecektir. 28x28 girdi boyutu verildiğinde, dokuz adet 5x5 filtre uyguladıktan sonra 9x24x24'lük bir tensör elde edeceğiz (uzamsal boyut daha küçüktür, çünkü 5 uzunluğundaki bir kayma aralığının 28 piksele sığabileceği yalnızca 24 konum vardır).\n",
    "\n",
    "Evrişimden sonra, 9x24x24 tensörü 5184 boyutunda tek bir vektöre düzleştiriyoruz ve ardından 10 sınıf üretmek için doğrusal katman ekliyoruz. Ayrıca katmanlar arasında `relu` etkinleştirme fonksiyonunu kullanıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OneConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=1,out_channels=9,kernel_size=(5,5))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(5184,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.conv(x))\n",
    "        x = self.flatten(x)\n",
    "        x = nn.functional.log_softmax(self.fc(x),dim=1)\n",
    "        return x\n",
    "\n",
    "net = OneConv()\n",
    "\n",
    "summary(net,input_size=(1,1,28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tam bağlı çok katmanlı ağlardaki yaklaşık 80 bin tane ile karşılaştırıldığında, bu ağın yaklaşık 50 bin tane eğitilebilir parametre içerdiğini görebilirsiniz. Bu, daha küçük veri kümelerinde bile iyi sonuçlar elde etmemizi sağlar çünkü evrişimli ağlar çok daha iyi genelleştirir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = train(net,train_loader,test_loader,epochs=5)\n",
    "plot_results(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gördüğünüz gibi, önceki ünitedeki tam bağlı ağlara kıyasla daha yüksek doğruluk ve çok daha hızlı şekilde elde edebiliyoruz.\n",
    "\n",
    "Neler olup bittiğini biraz daha anlamaya çalışmak için eğitilmiş evrişimli katmanlarımızın ağırlıklarını da görselleştirebiliriz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,9)\n",
    "with torch.no_grad():\n",
    "    p = next(net.conv.parameters())\n",
    "    for i,x in enumerate(p):\n",
    "        ax[i].imshow(x.detach().cpu()[0,...])\n",
    "        ax[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu filtrelerden bazılarının bazı eğik hareketleri tanıyor gibi göründüğünü, diğerlerinin ise oldukça rastgele göründüğünü görebilirsiniz.\n",
    "\n",
    "## Çok katmanlı CNN'ler ve ortaklama katmanları\n",
    "\n",
    "İlk evrişimli katmanlar, yatay veya dikey çizgiler gibi ilkel örüntüleri arar, ancak ilkel şekiller gibi daha yüksek seviyeli örüntüleri aramak için bunların üzerine başka evrişimli katmanlar uygulayabiliriz. Daha sonra daha evrişimli katmanlar, bu şekilleri, sınıflandırmaya çalıştığımız son nesneye kadar resmin bazı kısımlarında birleştirebilir.\n",
    "\n",
    "Bunu yaparken bir püf noktası da uygulayabiliriz: İmgenin uzamsal boyutunu azaltmak. Kayan 3x3 pencerede yatay bir hareket olduğunu tespit ettikten sonra, bunun tam olarak hangi pikselde meydana geldiği çok önemli değildir. Böylece **ortaklama katmanlarından** birini kullanarak imgenin boyutunu \"küçültebiliriz\":\n",
    "\n",
    "* **Ortalama Ortaklama** kayan bir pencere alır (örneğin, 2x2 piksel) ve pencere içindeki değerlerin ortalamasını hesaplar.\n",
    "* **Azami (Maksimum) Ortaklama**, pencereyi maksimum değerle değiştirir. Maksimum ortaklamanın arkasındaki fikir, kayan pencerede belirli bir örüntünün varlığını tespit etmektir.\n",
    "\n",
    "Bu nedenle, tipik bir CNN'de, imgenin boyutlarını azaltmak için aralarında ortaklama katmanları olan birkaç evrişimli katman olacaktır. Ayrıca filtre sayısını da artıracağız, çünkü örüntüler daha gelişmiş hale geldikçe aramamız gereken daha olası ilginç kombinasyonlar vardır.\n",
    "\n",
    "![Ortaklama katmanlarına sahip birkaç evrişimli katmanı gösteren bir imge.](../images/cnn-pyramid.png)\n",
    "\n",
    "Uzamsal boyutların küçülmesi ve öznitelik/filtre boyutlarının artması nedeniyle bu mimariye **piramit mimarisi** de denir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiLayerCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(10, 20, 5)\n",
    "        self.fc = nn.Linear(320,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 320)\n",
    "        x = nn.functional.log_softmax(self.fc(x),dim=1)\n",
    "        return x\n",
    "\n",
    "net = MultiLayerCNN()\n",
    "summary(net,input_size=(1,1,28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu tanımla ilgili birkaç şeye dikkat edin:\n",
    "\n",
    "* `Flatten` katmanını kullanmak yerine `forward` fonksiyonu içinde `view` fonksiyonu ile tensörü düzleştiriyoruz. Düzleştirme katmanının eğitilebilir ağırlıkları olmadığından, sınıfımızda ayrı bir katman örneği oluşturmamız şart değildir.\n",
    "* Modelimizde yalnızca bir ortaklama katmanı örneği kullanıyoruz, çünkü bu aynı zamanda eğitilebilir herhangi bir parametre içermez ve bu tek örnek etkili bir şekilde yeniden kullanılabilir.\n",
    "* Eğitilebilir parametrelerin sayısı (~8.5 bin), önceki durumlardan önemli ölçüde daha azdır. Bunun nedeni, genel olarak evrişimli katmanların birkaç parametreye sahip olması ve son yoğun katman uygulanmadan önce imgenin boyutsallığının önemli ölçüde azalmasıdır. Az sayıda parametrenin modellerimiz üzerinde olumlu etkisi vardır çünkü bu, daha küçük veri kümesi boyutlarında bile aşırı öğrenmeyi önlemeye yardımcı olur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = train(net,train_loader,test_loader,epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muhtemelen gözlemlemeniz gereken şey, yalnızca bir katmandan daha yüksek doğruluk elde edebildiğimizdir ve çok daha hızlıdır - yalnızca 1 veya 2 dönem. Bu, gelişmiş ağ mimarisinin, neler olup bittiğini anlamak ve imgelerimizden genel örüntüleri çıkarmak için çok daha az veriye ihtiyaç duyduğu anlamına gelir.\n",
    "\n",
    "## CIFAR-10 veri kümesinden gerçek imgelerle oynama\n",
    "\n",
    "El yazısı rakamları tanıma problemimiz bir basit problem gibi görünse de, artık daha ciddi bir şey yapmaya hazırız. Farklı nesnelerin resimlerinden oluşan [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) adlı daha gelişmiş veri kümesini keşfedelim. 10 sınıfa ayrılmış 60 bin 32x32 imge içerir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=14, shuffle=True)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=14, shuffle=False)\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_dataset(trainset,classes=classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR-10 için iyi bilinen bir mimariye [LeNet](https://en.wikipedia.org/wiki/LeNet) adı verilir ve *Yann LeCun* tarafından önerilmiştir. Yukarıda özetlediğimizle aynı ilkeleri takip eder, ana fark 1 yerine 3 renkli girdi kanalıdır.\n",
    "\n",
    "Ayrıca bu modele bir basitleştirme daha yapıyoruz - çıktı etkinleştirme işlevi olarak `log_softmax` kullanmıyoruz ve sadece son tam bağlı katmanın çıktısını döndürüyoruz. Bu durumda modeli optimize etmek için `CrossEntropyLoss` kayıp işlevini kullanabiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.conv3 = nn.Conv2d(16,120,5)\n",
    "        self.flat = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(120,64)\n",
    "        self.fc2 = nn.Linear(64,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = nn.functional.relu(self.conv3(x))\n",
    "        x = self.flat(x)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "net = LeNet()\n",
    "\n",
    "summary(net,input_size=(1,3,32,32))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu ağın düzgün bir şekilde eğitilmesi önemli miktarda zaman alacaktır ve tercihen GPU etkin hesaplama ile yapılmalıdır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.SGD(net.parameters(),lr=0.001,momentum=0.9)\n",
    "hist = train(net, trainloader, testloader, epochs=3, optimizer=opt, loss_fn=nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 dönemlik eğitimle elde edebildiğimiz doğruluk çok iyi görünmüyor. Ancak, kör tahminin bize yalnızca %10 doğruluk sağlayacağını ve sorunumuzun aslında MNIST rakam sınıflandırmasından önemli ölçüde daha zor olduğunu unutmayın. Bu kadar kısa bir eğitim süresinde %50'nin üzerine çıkmak iyi bir başarı gibi görünüyor.\n",
    "\n",
    "## Ana Fikirler\n",
    "\n",
    "Bu ünitede, bilgisayarla görme sinir ağlarının arkasındaki ana kavramı öğrendik - evrişimli ağlar. İmge sınıflandırmasına, nesne algılamaya ve hatta imge üretme ağlarına güç veren gerçek yaşam mimarilerinin tümü, yalnızca daha fazla katman ve bazı ek eğitim püf noktaları ile CNN'lere dayanmaktadır."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
