{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evrişimli sinir ağları\n",
    "\n",
    "Sinir ağlarının imgelerle başa çıkmada oldukça iyi olduğunu ve tek katmanlı algılayıcının bile MNIST veri kümesinden el yazısı rakamları makul bir doğrulukla tanıyabildiğini daha önce gördük. Ancak, MNIST veri kümesi çok özeldir ve tüm rakamlar imgenin içinde ortalanmıştır, bu da görevi kolaylaştırır.\n",
    "\n",
    "Gerçek hayatta, resimdeki nesneleri, resimdeki tam konumlarından bağımsız olarak tanıyabilmek istiyoruz. Bilgisayarla görme, genel sınıflandırmadan farklıdır çünkü resimde belirli bir nesneyi bulmaya çalışırken, belirli **örüntüleri** ve bunların kombinasyonlarını arayarak imgeyi tarıyoruz. Örneğin, bir kedi ararken, önce bıyık oluşturabilen yatay çizgilere bakabiliriz ve ardından belirli bir bıyık kombinasyonu bize bunun aslında bir kedi resmi olduğunu söyleyebilir. İmge üzerindeki tam konumları değil, belirli örüntülerin göreli konumu ve varlığı önemlidir.\n",
    "\n",
    "Örüntüleri çıkarmak için **evrişimli filtreler** kavramını kullanacağız. Ama önce önceki ünitelerde tanımladığımız tüm bağımlılıkları ve fonksiyonları yükleyelim. Kodu kısa ve temiz tutmak için bu not defterinde tanımlamak istemediğimiz bazı yararlı işlevleri içeren tfcv yardımcı kütüphanesini de içe aktaracağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tfcv import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu örnekte daha önce gördüğümüz MNIST veri kümesine ve imge sınıflandırmasına odaklanacağız. Keras yerleşik fonksiyonlarını kullanıp veri kümesini yükleyerek başlayacağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.astype(np.float32) / 255.0\n",
    "x_test = x_test.astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evrişimli filtreler\n",
    "\n",
    "Evrişimli filtreler, imgenin her pikseli üzerinde çalışan ve komşu piksellerin ağırlıklı ortalamasını hesaplayan küçük pencerelerdir.\n",
    "\n",
    "\n",
    "Ağırlık katsayılarının matrisleriyle tanımlanırlar. MNIST el yazısı rakamlarımız üzerinde iki farklı evrişimli filtre uygulama örneklerini görelim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_convolution(x_train[:5],[[-1.,0.,1.],[-1.,0.,1.],[-1.,0.,1.]],'Dikey kenar filtresi')\n",
    "plot_convolution(x_train[:5],[[-1.,-1.,-1.],[0.,0.,0.],[1.,1.,1.]],'Yatay kenar filtresi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "İlk filtre **dikey kenar filtresi** olarak adlandırılır ve aşağıdaki matris ile tanımlanır:\n",
    "$$\n",
    "\\left(\n",
    "    \\begin{matrix}\n",
    "     -1 & 0 & 1 \\cr\n",
    "     -1 & 0 & 1 \\cr\n",
    "     -1 & 0 & 1 \\cr\n",
    "    \\end{matrix}\n",
    "\\right)\n",
    "$$\n",
    "Bu filtre nispeten düzgün bir piksel alanı üzerinden geçtiğinde, tüm değerler 0'a toplar. Ancak, imgede dikey bir kenarla karşılaştığında, yüksek uç değer üretilir. Bu nedenle yukarıdaki imgelerde dikey kenarların yüksek ve düşük değerlerle temsil edildiğini, yatay kenarların ise ortalamasının alındığını görebilirsiniz.\n",
    "\n",
    "Yatay kenar filtresi uyguladığımızda tam tersi bir şey olur - yatay çizgiler büyütülür ve dikey çizgiler ortalanır.\n",
    "\n",
    "Klasik bilgisayarla görmede, öznitelikler oluşturmak için imgeye birden çok filtre uygulandı ve bunlar daha sonra bir sınıflandırıcı oluşturmak için makine öğrenmesi algoritması tarafından kullanıldı. Bu filtreler aslında bazı hayvanların görme sistemlerinde bulunan sinir yapılarına benzer.\n",
    "\n",
    "<img src=\"../images/lmfilters.jpg\" width=\"400\"/>\n",
    "\n",
    "Bununla birlikte, derin öğrenmede, sınıflandırma problemini çözmek için en iyi evrişimli filtreleri **öğrenen** ağlar oluştururuz. Bunu yapmak için **evrişimli katmanları** tanıtıyoruz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evrişimli Katmanlar\n",
    "\n",
    "Evrişimli katmanın ağırlıklarını eğitilebilir hale getirmek için, imgeye evrişimli filtre penceresi uygulama sürecini bir şekilde matris işlemlerine indirgememiz gerekir, bu işlemler daha sonra geri yayma eğitimine tabi olabilir. Bunu yapmak için **im2col** adını verdiğimiz akıllı bir matris dönüşümü kullanıyoruz.\n",
    "\n",
    "Aşağıdaki piksellere sahip küçük bir $\\mathbf{x}$ imgemiz olduğunu varsayalım:\n",
    "\n",
    "$$\n",
    "\\mathbf{x} = \\left(\n",
    "         \\begin{array}{ccccc}\n",
    "           a & b & c & d & e \\\\\n",
    "           f & g & h & i & j \\\\\n",
    "           k & l & m & n & o \\\\\n",
    "           p & q & r & s & t \\\\\n",
    "           u & v & w & x & y \\\\\n",
    "         \\end{array}\n",
    "     \\right)\n",
    "$$\n",
    "\n",
    "Ayrıca aşağıdaki ağırlıklara sahip iki dönüştürme filtresini uygulamak istiyoruz:\n",
    "$$\n",
    "W^{(i)} = \\left(\\begin{array}{ccc}\n",
    "            w^{(i)}_{00} & w^{(i)}_{01} & w^{(i)}_{02} \\\\\n",
    "            w^{(i)}_{10} & w^{(i)}_{11} & w^{(i)}_{12} \\\\\n",
    "            w^{(i)}_{20} & w^{(i)}_{21} & w^{(i)}_{22} \\\\\n",
    "            \\end{array}\\right) \n",
    "$$\n",
    "\n",
    "Evrişimi uygularken, sonucun ilk pikseli, öğe bazında çarpılarak elde edilir.\n",
    "$\\left(\\begin{array}{ccc}\n",
    "  a & b & c \\\\\n",
    "  f & g & h \\\\\n",
    "  k & l & m \\\\\n",
    "\\end{array}\\right)$  $W^{(i)}$, ikinci eleman bununla çarparak $\\left(\\begin{array}{ccc}\n",
    "  b & c & d \\\\\n",
    "  g & h & i \\\\\n",
    "  l & m & n \\\\\n",
    "\\end{array}\\right)$ $W^{(i)}$, ve böyle devam eder.\n",
    "\n",
    "Bu işlemi formüle dökmek için, $x$ orijinal imgenin tüm $3\\times3$ parçalarını aşağıdaki matrise çıkaralım:\n",
    "\n",
    "$$\n",
    "\\mathrm{im2col}(x) = \\left[\n",
    "        \\begin{array}{cccccc}\n",
    "          a & b & \\ldots & g & \\ldots & m \\\\\n",
    "          b & c & \\ldots & h & \\ldots & n \\\\\n",
    "          c & d & \\ldots & i & \\ldots & o \\\\\n",
    "          f & g & \\ldots & l & \\ldots & r \\\\\n",
    "          g & h & \\ldots & m & \\ldots & s \\\\\n",
    "          h & i & \\ldots & n & \\ldots & t \\\\\n",
    "          k & l & \\ldots & q & \\ldots & w \\\\\n",
    "          l & m & \\ldots & r & \\ldots & x \\\\\n",
    "          m & n & \\ldots & s & \\ldots & y \\\\\n",
    "        \\end{array}\n",
    "    \\right]\n",
    "$$\n",
    "\n",
    "Bu matrisin her bir sütunu, orijinal imgenin her bir $3\\times3$ alt bölgesine karşılık gelir. Şimdi, evrişimin sonucunu elde etmek için, bu matrisi matris veya ağırlıklarla çarpmamız yeterlidir.\n",
    "\n",
    "$$\n",
    "\\mathbf{W} = \\left[\n",
    "         \\begin{array}{cccccccc}\n",
    "            w^{(0)}_{00} & w^{(0)}_{01} & w^{(0)}_{02} & w^{(0)}_{10} & w^{(0)}_{11} & \\ldots & w^{(0)}_{21} & w^{(0)}_{22} \\\\\n",
    "            w^{(1)}_{00} & w^{(1)}_{01} & w^{(1)}_{02} & w^{(1)}_{10} & w^{(1)}_{11} & \\ldots & w^{(1)}_{21} & w^{(1)}_{22} \\\\\n",
    "         \\end{array}\n",
    "       \\right]\n",
    "$$\n",
    "(bu matrisin her satırı, bir satıra düzleştirilmiş $i$. filtrenin ağırlıklarını içerir)\n",
    "\n",
    "Bu nedenle, orijinal imgeye bir evrişim filtresinin uygulanması, geri yayma kullanarak nasıl başa çıkacağımızı zaten bildiğimiz matris çarpımı ile değiştirilebilir:\n",
    "$$\n",
    "C(x) = W\\times\\mathbf{im2col}(x)\n",
    "$$\n",
    "\n",
    "Evrişimli katmanlar, `Conv2d` sınıfı kullanılarak tanımlanır. Aşağıdakileri belirtmemiz gerekiyor:\n",
    "* `filters` - kullanılacak filtre sayısı. 9 farklı filtre kullanacağız, bu da ağa senaryomuz için hangi filtrelerin en iyi şekilde çalıştığını keşfetme fırsatı verecektir.\n",
    "* `kernel_size` kayan pencerenin boyutudur. Genellikle 3x3 veya 5x5 filtreler kullanılır.\n",
    "\n",
    "En basit CNN, bir evrişimli katman içerecektir. 28x28 girdi boyutu verildiğinde, dokuz adet 5x5 filtre uyguladıktan sonra 24x24x9'luk bir tensör elde edeceğiz. Uzamsal boyut daha küçüktür, çünkü 5 uzunluğundaki bir kayma aralığının 28 piksele sığabileceği yalnızca 24 konum vardır.\n",
    "\n",
    "Evrişimden sonra, 24x24x9 tensörü 5184 boyutunda tek bir vektöre düzleştiriyoruz ve ardından 10 sınıf üretmek için doğrusal katman ekliyoruz. Ayrıca katmanlar arasında `relu` etkinleştirme fonksiyonunu kullanıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=9, kernel_size=(5,5), input_shape=(28,28,1),activation='relu'),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.compile(loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tam bağlı çok katmanlı ağlardaki yaklaşık 80 bin parametre ile karşılaştırıldığında, bu ağın yaklaşık 50 bin eğitilebilir parametre içerdiğini görebilirsiniz. Bu, daha küçük veri kümelerinde bile iyi sonuçlar elde etmemizi sağlar çünkü evrişimli ağlar çok daha iyi genelleşir.\n",
    "\n",
    "> **Not**: Pratik durumların çoğunda, renkli imgelere evrişimli katmanlar uygulamak isteriz. Bu nedenle, `Conv2D` katmanı girdinin $W\\times H\\times C$ şeklinde olmasını bekler; burada $W$ ve $H$ imgenin genişliği ve yüksekliğidir ve $C$ renk kanallarının sayısıdır . Gri tonlamalı imgeler için $C=1$ ile aynı şekle ihtiyacımız var.\n",
    "\n",
    "Eğitime başlamadan önce verilerimizi yeniden şekillendirmemiz gerekiyor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_c = np.expand_dims(x_train,3)\n",
    "x_test_c = np.expand_dims(x_test,3)\n",
    "hist = model.fit(x_train_c,y_train,validation_data=(x_test_c,y_test),epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gördüğünüz gibi, önceki üniteden tam bağlı ağlara kıyasla daha yüksek doğruluk ve çok daha fazla hız (dönem sayısı açısından) elde edebiliyoruz. Ancak, eğitimin kendisi daha fazla kaynak gerektirir ve GPU olmayan bilgisayarlarda daha yavaş olabilir.\n",
    "\n",
    "## Evrişimli Katmanları Görselleştirme\n",
    "\n",
    "Neler olup bittiğini biraz daha anlamaya çalışmak için eğitilmiş evrişimli katmanlarımızın ağırlıklarını da görselleştirebiliriz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,9)\n",
    "l = model.layers[0].weights[0]\n",
    "for i in range(9):\n",
    "    ax[i].imshow(l[...,0,i])\n",
    "    ax[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu filtrelerden bazılarının bazı eğik hareketleri tanıyor gibi göründüğünü, diğerlerinin ise oldukça rastgele göründüğünü görebilirsiniz.\n",
    "\n",
    "> **Görev**: Aynı ağı 3x3 filtrelerle eğitin ve görselleştirin. Daha tanıdık örüntüler görüyor musunuz?\n",
    "\n",
    "## Çok katmanlı CNN'ler ve ortaklama katmanları\n",
    "\n",
    "İlk evrişimli katmanlar, yatay veya dikey çizgiler gibi ilkel örüntüleri arar, ancak ilkel şekiller gibi daha yüksek seviyeli örüntüleri aramak için bunların üzerine başka evrişimli katmanlar uygulayabiliriz. Daha sonra daha fazla evrişimli katman, bu şekilleri, sınıflandırmaya çalıştığımız son nesneye kadar resmin bazı kısımlarında birleştirebilir.\n",
    "\n",
    "Bunu yaparken bir numara da uygulayabiliriz: İmgenin uzamsal boyutunu azaltmak. Kayan 3x3 pencerede yatay bir hareket olduğunu tespit ettikten sonra, bunun tam olarak hangi pikselde meydana geldiği çok önemli değildir. Böylece **ortaklama katmanlarından** birini kullanarak imgenin boyutunu \"küçültebiliriz\":\n",
    "\n",
    "* **Ortalama Ortaklama** kayan bir pencere alır (örneğin, 2x2 piksel) ve pencere içindeki değerlerin ortalamasını hesaplar.\n",
    "* **Azami (Maksimum) Ortaklama**, pencereyi maksimum değerle değiştirir. Maksimum ortaklamanın arkasındaki fikir, kayan pencerede belirli bir örüntünün varlığını tespit etmektir.\n",
    "\n",
    "Bu nedenle, tipik bir CNN'de, imgenin boyutlarını azaltmak için aralarında ortaklama katmanları olan birkaç evrişimli katman olacaktır. Ayrıca filtre sayısını da artıracağız, çünkü örüntüler daha gelişmiş hale geldikçe aramamız gereken daha olası ilginç kombinasyonlar vardır.\n",
    "\n",
    "![Ortaklama katmanlarına sahip birkaç evrişimli katmanı gösteren bir imge.](../images/cnn-pyramid.png)\n",
    "\n",
    "Uzamsal boyutların küçülmesi ve öznitelik/filtre boyutlarının artması nedeniyle bu mimariye **piramit mimarisi** de denir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=10, kernel_size=(5,5), input_shape=(28,28,1),activation='relu'),\n",
    "    keras.layers.MaxPooling2D(),\n",
    "    keras.layers.Conv2D(filters=20, kernel_size=(5,5), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(),    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.compile(loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eğitilebilir parametre sayısının (~8.5 bin) önceki durumlardan çok daha az olduğuna dikkat edin. Bunun nedeni, genel olarak evrişimli katmanların birkaç parametreye sahip olması ve son yoğun katman uygulanmadan önce imgenin boyutsallığının önemli ölçüde azalmasıdır. Az sayıda parametrenin modellerimiz üzerinde olumlu etkisi vardır çünkü bu, daha küçük veri kümesi boyutlarında bile aşırı öğrenmeyi önlemeye yardımcı olur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(x_train_c,y_train,validation_data=(x_test_c,y_test),epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muhtemelen gözlemlemeniz gereken şey, yalnızca bir katmanla olduğundan daha yüksek doğruluk elde edebildiğimizdir ve dönem sayısı açısından çok daha hızlıdır - sadece 1 veya 2 dönem. Bu, gelişmiş ağ mimarisinin, neler olup bittiğini anlamak ve imgelerimizden genel örüntüleri çıkarmak için çok daha az veriye ihtiyaç duyduğu anlamına gelir. Ancak, eğitim de daha uzun sürer ve bir GPU gerektirir.\n",
    "\n",
    "## CIFAR-10 veri kümesinden gerçek imgelerle oynama\n",
    "\n",
    "El yazısı rakamları tanıma problemimiz bir basit problem gibi görünse de, artık daha ciddi bir şey yapmaya hazırız. Farklı nesnelerin resimlerinden oluşan [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) adlı daha gelişmiş veri kümesini keşfedelim. 10 sınıfa ayrılmış 60 bin 32x32 imge içerir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = keras.datasets.cifar10.load_data()\n",
    "x_train = x_train.astype(np.float32) / 255.0\n",
    "x_test = x_test.astype(np.float32) / 255.0\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_dataset(x_train,y_train,classes=classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR-10 için iyi bilinen bir mimariye [LeNet](https://en.wikipedia.org/wiki/LeNet) adı verilir ve *Yann LeCun* tarafından önerilmiştir. Yukarıda özetlediğimizle aynı ilkeleri takip eder, ana fark 1 yerine 3 renkli girdi kanalıdır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters = 6, kernel_size = 5, strides = 1, activation = 'relu', input_shape = (32,32,3)),\n",
    "    keras.layers.MaxPooling2D(pool_size = 2, strides = 2),\n",
    "    keras.layers.Conv2D(filters = 16, kernel_size = 5, strides = 1, activation = 'relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size = 2, strides = 2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(120, activation = 'relu'),\n",
    "    keras.layers.Dense(84, activation = 'relu'),\n",
    "    keras.layers.Dense(10, activation = 'softmax')])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu ağın düzgün bir şekilde eğitilmesi önemli miktarda zaman alacaktır ve tercihen GPU etkin hesaplama ile yapılmalıdır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['acc'])\n",
    "hist = model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Birkaç eğitim dönemiyle elde edebildiğimiz doğruluk çok büyük görünmüyor. Bununla birlikte, kör tahmininin bize yalnızca %10 doğruluk sağlayacağını ve sorunumuzun aslında MNIST rakam sınıflandırmasından önemli ölçüde daha zor olduğunu unutmayın. Bu kadar kısa bir eğitim süresinde %50'nin üzerine çıkmak iyi bir başarı gibi görünüyor.\n",
    "\n",
    "## Ana Fikirler\n",
    "\n",
    "Bu ünitede, bilgisayarla görme sinir ağlarının arkasındaki ana kavramı öğrendik - evrişimli ağlar. İmge sınıflandırmasına, nesne algılamaya ve hatta imge üretme ağlarına güç veren gerçek yaşam mimarilerinin tümü, yalnızca daha fazla katman ve bazı ek eğitim püf noktaları ile CNN'lere dayanmaktadır."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0cb620c6d4b9f7a635928804c26cf22403d89d98d79684e4529119355ee6d5a5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
