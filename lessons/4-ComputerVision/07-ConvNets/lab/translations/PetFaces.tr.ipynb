{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evcil Hayvan Yüzlerinin Sınıflandırılması\n",
    "\n",
    "[Yeni Başlayanlar için YZ Müfredatı](https://github.com/microsoft/ai-for-beginners)'dan Laboratuvar Ödevi.\n",
    "\n",
    "### Verileri Alma\n",
    "\n",
    "Bu ödevde, nispeten basit bir sınıflandırma görevi olan evcil hayvan yüzlerinin sınıflandırılmasına odaklanacağız. Bu veri kümesi, [Oxford-IIIT Veri Kümesi](https://www.robots.ox.ac.uk/~vgg/data/pets/)'dan kesilmiş yüzlerden oluşur. Veri kümesini yükleyip görselleştirerek başlayalım.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://mslearntensorflowlp.blob.core.windows.net/data/petfaces.tar.gz\n",
    "!tar xfz petfaces.tar.gz\n",
    "!rm petfaces.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bir listeden bir dizi imgeyi görüntülemek için genel işlevi tanımlayacağız:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def display_images(l,titles=None,fontsize=12):\n",
    "    n=len(l)\n",
    "    fig,ax = plt.subplots(1,n)\n",
    "    for i,im in enumerate(l):\n",
    "        ax[i].imshow(im)\n",
    "        ax[i].axis('off')\n",
    "        if titles is not None:\n",
    "            ax[i].set_title(titles[i],fontsize=fontsize)\n",
    "    fig.set_size_inches(fig.get_size_inches()*n)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi tüm sınıf alt dizinlerini dolaşalım ve her sınıfın ilk birkaç imgesini çizelim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls in os.listdir('petfaces'):\n",
    "    print(cls)\n",
    "    display_images([Image.open(os.path.join('petfaces',cls,x)) \n",
    "                    for x in os.listdir(os.path.join('petfaces',cls))[:10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veri kümemizdeki sınıf sayısını da tanımlayalım:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(os.listdir('petfaces'))\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veri kümesini Derin Öğrenme için Hazırlama\n",
    "\n",
    "As you have seen from the pictures above, all of them are close to square image ratio, so we need to resize all images to square size. Also, we can organize images in minibatches.\n",
    "\n",
    "Sinir ağımızı eğitmeye başlamak için, tüm imgeleri tensörlere dönüştürmemiz ve ayrıca etiketlere (sınıf sayıları) karşılık gelen tensörler oluşturmamız gerekir. Çoğu sinir ağı çerçevesi, imgelerle uğraşmak için basit araçlar içerir:\n",
    "* Tensorflow'ta `tf.keras.preprocessing.image_dataset_from_directory` kullanın\n",
    "* PyTorch'ta `torchvision.datasets.ImageFolder` kullanın\n",
    "\n",
    "Yukarıdaki resimlerden de gördüğünüz gibi, hepsi kare imge oranına yakın, bu nedenle tüm resimleri kare boyutuna getirmemiz gerekiyor. Ayrıca imgeleri minigruplar halinde düzenleyebiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERİ KÜMESİNİ YÜKLEMEYİ KODLA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi veri kümesini eğitim ve test parçalarına ayırmamız gerekiyor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EĞİTİM/TEST AYRIMINI KODLA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi veri kümemizdeki tensörlerin boyutunu yazdıralım. Her şeyi doğru yaptıysanız, eğitim öğelerinin boyutu\n",
    "  * Tensorflow için `(batch_size,image_size,image_size,3)`, PyTorch için `batch_size,3,image_size,image_size` olmalı\n",
    "  * Etiketler için `batch_size` olmalı\n",
    "\n",
    "  Etiketler sınıfın sayısını içermelidir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensör boyutlatının yazdır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veriyi göster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bir Sinir Ağı Tanımlama\n",
    "\n",
    "İmge sınıflandırma için muhtemelen birkaç katmana sahip evrişimli bir sinir ağı tanımlamanız gerekir. Nelere dikkat edilmeliyiz:\n",
    "* Piramit mimarisini unutmayın, yani derine inildikçe filtre sayısı artmalıdır.\n",
    "* Katmanlar (ReLU) ve Maksimum Ortaklama arasındaki etkinleştirme fonksiyonlarını unutmayın.\n",
    "* Nihai sınıflandırıcı gizli katmanlı veya katmansız olabilir, ancak çıktı nöronlarının sayısı sınıf sayısına eşit olmalıdır.\n",
    "\n",
    "Önemli olan son katmandaki etkinleştirme fonksiyonunu ve kayıp fonksiyonunu doğru yapmaktır:\n",
    "* Tensorflow'ta etkinleştirme olarak `softmax`  ve kayıp olarak `sparse_categorical_crossentropy` kullanabilirsiniz. Seyrek kategorik çapraz entropi ile seyrek olmayan arasındaki fark, ilkinin çıktıyı birebir vektör olarak değil, sınıf sayısı olarak beklemesidir.\n",
    "* PyTorch'ta etkinleştirme fonksiyonu olmadan son katmana sahip olabilir ve `CrossEntropyLoss` kayıp fonksiyonunu kullanabilirsiniz. Bu işlev, softmaksi otomatik olarak uygular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SİNİR AĞINI TANIMLAMAK İÇİN KODLA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sinir Ağını Eğitme\n",
    "\n",
    "Artık sinir ağını eğitmeye hazırız. Eğitim sırasında, lütfen her dönemde eğitim ve test verilerinin doğruluğunu toplayın ve ardından aşırı öğrenme olup olmadığını görmek için doğruluğu çizdirin.\n",
    "\n",
    "> Eğitimi hızlandırmak için varsa GPU kullanmanız gerekir. TensorFlow/Keras GPU'yu otomatik olarak kullanacak olsa da, PyTorch'ta GPU hızlandırmasından yararlanmak için eğitim sırasında `.to()` yöntemini kullanarak hem modeli hem de verileri GPU'ya taşımanız gerekir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AĞI EĞİT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eğitim ve geçerleme veri kümesinde doğruluğu çizdirin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aşırı öğrenme hakkında ne söyleyebilirsiniz? Modelin doğruluğunu artırmak için neler yapılabilir?\n",
    "\n",
    "## İsteğe bağlı: İlk 3 Doğruluğunu Hesaplama\n",
    "\n",
    "Bu alıştırmada, oldukça yüksek sayıda sınıfla (35) sınıflandırma ile uğraşıyorduk, dolayısıyla sonucumuz - yaklaşık %50 geçerleme doğruluğu - oldukça iyi. Standart ImageNet veri kümesinde daha da fazlası vardır - 1000 sınıf.\n",
    "\n",
    "Bu gibi durumlarda, modelin **her zaman** sınıfı doğru tahmin etmesini sağlamak zordur. İki cinsin birbirine çok benzediği durumlar vardır ve model çok benzer olasılıklar verir (örn. 0.45 ve 0.43). Standart doğruluğu ölçersek, model çok küçük bir hata yapmış olsa bile yanlış bir durum olarak kabul edilecektir. Bundan dolayı genellikle başka bir metriği ölçeriz - modelin en olası ilk 3 tahmini içindeki doğruluk.\n",
    "\n",
    "Hedef etiketi ilk 3 model tahmininde yer alıyorsa, durumu doğru kabul ederiz.\n",
    "\n",
    "Test veri kümesindeki ilk 3 doğruluğu hesaplamak için veri kümesini manuel olarak gözden geçirmeniz, tahmini almak için sinir ağını uygulamanız ve ardından hesaplamaları yapmanız gerekir. Birkaç ipucu:\n",
    "\n",
    "* Tensorflow'da, \"`predictions`'in (modelin çıktısı) `targets`'a (hedef değerler) göre en ilk-k'da olup olmadığını (parametre olarak `k=3` geçirin) görmek için `tf.nn.in_top_k` işlevini kullanın. Bu işlev, `tf.cast` kullanılarak `int`'e dönüştürülebilen ve ardından `tf.reduce_sum` kullanılarak toplanabilen bir boole değerleri tensörü döndürür.\n",
    "* PyTorch'ta `torch.topk` fonksiyonunu kullanarak daha yüksek olasılıklı sınıfların indekslerini alabilir ve ardından doğru sınıfın onlara ait olup olmadığına bakabilirsiniz. Daha fazla ipucu için [buna](https://gist.github.com/weiaicunzai/2a5ae6eac6712c70bde0630f3e76b77b) bakın."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# İLK-3 DOĞRULUĞUNU HESAPLA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## İsteğe Bağlı: Kedi ve Köpek Sınıflandırması Oluşturma\n",
    "\n",
    "Aynı veri kümesinde ikili kedilere karşı köpekler sınıflandırmamızın ne kadar doğru olacağını da görmek istiyoruz. Bunu yapmak için etiketleri düzenlememiz gerekiyor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yalnızca iki etiket içeren veri kümesini tanımlayın: 0 = kedi, 1 = köpek\n",
    "# İpucu: Hangisinin hangisi olduğunu anlamak için sınıf adı öneki kullanın"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sinir ağı mimarisini tanımlayın ve eğitin"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "86193a1ab0ba47eac1c69c1756090baa3b420b3eea7d4aafab8b85f8b312f0c5"
  },
  "kernelspec": {
   "display_name": "py37_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
